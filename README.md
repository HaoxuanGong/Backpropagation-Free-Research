# Novel Backpropagation-Free Deep Neural Network


## Abstract
There is immense interest in developing and deploying deep neural networks to solve complex problems in many challenging areas, such as speech recognition and image semantics extraction. Neural networks (NN) generally act as a black box that can classify signals end-to-end without knowing the essence of the processed signal. That is contrary to the statistical approaches; they need a profound understanding of the analysed signal to extract suitable features besides mastering the classical machine learning techniques to classify the desired outcomes. The NN requires training to discover the underlying structure of the data and is dependent on heuristics and intuitions to choose the needed hyperparameters. The recent insurgence of NN, after many years of recession, is due to the introduction of the Deep Convolutional Neural Network (DCNN) paradigm that involves many layers using new training techniques. Current models use a backpropagation process, which has limitations in expressing the embedded knowledge and slow processing and training speed. We will develop a new mathematical model verified experimentally for the DCNN, which does not use the backpropagation process. We are looking for Artificial Intelligence, Neural Networks, and Machine Learning in a successful applicant. Mastering Python Language. Has an excellent background in maths. Objectives This project is about introducing a new theoretically derived model for deep neural networks for processing big data. The main difference from the current deep neural networks is it does not have the time-consuming backpropagation stage. The semantics of the embedded knowledge within it can also be more approachable to interpret. The mathematical model should be supported by experiments on big data from different datasets to validate the theoretical results.

## Documentation
- [Progress Report](https://docs.google.com/document/d/1CJWu6c23NiXX7k_KrFe4Z6F2GzBmsI0nT1therIx3bI/edit?usp=sharing)
