{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-05T13:16:27.997447400Z",
     "start_time": "2024-09-05T13:16:27.155328500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (0.17.1+cu121)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: torch==2.2.1+cu121 in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from torchvision) (2.2.1+cu121)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from torch==2.2.1+cu121->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from torch==2.2.1+cu121->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from torch==2.2.1+cu121->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from torch==2.2.1+cu121->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from torch==2.2.1+cu121->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from torch==2.2.1+cu121->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from jinja2->torch==2.2.1+cu121->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\study notes\\part iv project\\backpropagation-free-research\\venv\\lib\\site-packages (from sympy->torch==2.2.1+cu121->torchvision) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "number_of_epochs = 1\n",
    "learning_rate = 0.06"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-05T13:16:28.037454100Z",
     "start_time": "2024-09-05T13:16:27.995447300Z"
    }
   },
   "id": "c5548f160831f320"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]  # Normalize the images to [-1, 1]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=6000,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=6000,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "def one_hot_encode(labels, num_classes=10):\n",
    "    \"\"\" Converts a batch of labels to one-hot encoded format. \"\"\"\n",
    "    batch_size = labels.size(0)\n",
    "    one_hot_labels = torch.zeros(batch_size, num_classes, device=labels.device)\n",
    "    one_hot_labels.scatter_(1, labels.unsqueeze(1), 1)\n",
    "    return one_hot_labels\n",
    "\n",
    "\n",
    "def create_positive_data(data, labels):\n",
    "    \"\"\" Return original data and one-hot encoded labels. \"\"\"\n",
    "    one_hot_labels = one_hot_encode(labels, num_classes=10)\n",
    "    return data.cuda(), one_hot_labels.cuda()\n",
    "\n",
    "def create_negative_data(data, labels):\n",
    "    \"\"\" Create negative samples by randomly selecting different labels and return with one-hot encoded format. \"\"\"\n",
    "    batch_size = labels.size(0)\n",
    "    num_classes = 10\n",
    "    # Generate random labels different from the current labels\n",
    "    incorrect_labels = (labels + torch.randint(1, num_classes, (batch_size,), device=labels.device)) % num_classes\n",
    "    one_hot_labels = one_hot_encode(incorrect_labels, num_classes=10)\n",
    "    return data.cuda(), one_hot_labels.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-05T13:16:29.179562800Z",
     "start_time": "2024-09-05T13:16:28.013448Z"
    }
   },
   "id": "5eeba1dc1c103e8b"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "class CustomNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomNetwork, self).__init__()\n",
    "        # First hidden layer: Receives input and applies an 11x11 convolution\n",
    "        self.layer1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=11, padding=5, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=3)  # Batch normalization for 3 output channels\n",
    "        \n",
    "        # Second hidden layer: Takes the output of the first layer and applies another 11x11 convolution\n",
    "        self.layer2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=11, padding=5, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=3)  # Batch normalization for 3 output channels\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        self.hebbian_factors = torch.ones(2, 10, 3072, requires_grad=True, device='cuda')\n",
    "        self.hebbian_optimizer = optim.Adam([self.hebbian_factors], lr=learning_rate)\n",
    "        self.threshold = 0\n",
    "        \n",
    "    def soft_plus_loss(self, positive_goodness, negative_goodness, is_second_phase=False):\n",
    "        if is_second_phase:\n",
    "            threshold = self.threshold * 2\n",
    "        else:\n",
    "            threshold = self.threshold\n",
    "        return torch.log(1 + torch.exp(torch.cat([\n",
    "            -positive_goodness + threshold,\n",
    "            negative_goodness - threshold]))).mean()\n",
    "\n",
    "    def forward(self, x, layer_num):\n",
    "        \n",
    "        if layer_num == 0:\n",
    "            # Apply first hidden layer\n",
    "            x = self.layer1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = F.relu(x)\n",
    "        elif layer_num == 1:\n",
    "            # Apply second hidden layer\n",
    "            x = self.layer2(x)\n",
    "            x = self.bn2(x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        # Since no output layer is used, return the feature map from the last layer directly\n",
    "        return x\n",
    "    \n",
    "    def train_network(self, training_data_loader):\n",
    "        for _ in tqdm(range(number_of_epochs)):\n",
    "            for images, labels in training_data_loader:\n",
    "               positive_data, positive_labels = create_positive_data(images, labels)\n",
    "               negative_data, negative_labels = create_negative_data(images, labels)\n",
    "               \n",
    "               for i in range(2):\n",
    "                   hebbian_factors = self.hebbian_factors[i, :, :]\n",
    "                   positive_data = self.forward(positive_data, i)\n",
    "                   flattened_positive_data = positive_data.clone()\n",
    "                   flattened_positive_data = flattened_positive_data.view(flattened_positive_data.size(0), -1).detach()\n",
    "                   negative_data = self.forward(negative_data, i)\n",
    "                   flattened_negative_data = negative_data.clone()\n",
    "                   flattened_negative_data = flattened_negative_data.view(flattened_negative_data.size(0), -1).detach()\n",
    "                   \n",
    "                   \n",
    "                   negative_goodness = (torch.mm(negative_labels, hebbian_factors) * flattened_positive_data).mean(1)\n",
    "                   positive_goodness = (torch.mm(positive_labels, hebbian_factors) * flattened_negative_data).mean(1)\n",
    "                   loss = self.soft_plus_loss(positive_goodness, negative_goodness)\n",
    "                   self.optimizer.zero_grad()\n",
    "                   self.hebbian_optimizer.zero_grad()\n",
    "                   loss.backward()\n",
    "                   self.hebbian_optimizer.step()\n",
    "                   self.optimizer.step()\n",
    "                   \n",
    "    \n",
    "\n",
    "    def predict(self, testing_data_loader):\n",
    "        self.cuda()  # Ensure the model is on GPU\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, actual_labels in testing_data_loader:\n",
    "            images = images.cuda()  # Ensure images are on GPU\n",
    "            actual_labels = actual_labels.cuda()  # Ensure labels are on GPU\n",
    "            batch_size = images.size(0)\n",
    "            goodness_per_label = []\n",
    "    \n",
    "            for label in range(10):  # Assuming 10 classes\n",
    "                labels = torch.full((batch_size,), label, dtype=torch.long, device=images.device)\n",
    "                marked_data, one_hot_labels = create_positive_data(images, labels)\n",
    "                goodness = []\n",
    "    \n",
    "                for layer_num in range(2):  # Assuming 2 layers\n",
    "                    marked_data = self.forward(marked_data, layer_num)\n",
    "                    flattened_data = marked_data.view(marked_data.size(0), -1).detach()\n",
    "                    goodness_value = (torch.mm(one_hot_labels, self.hebbian_factors[layer_num, :, :]) * flattened_data).mean(1)\n",
    "                    goodness.append(goodness_value)\n",
    "    \n",
    "                goodness_per_label.append(torch.sum(torch.stack(goodness), dim=0).unsqueeze(1))\n",
    "    \n",
    "            goodness_per_label = torch.cat(goodness_per_label, 1)\n",
    "            predicted_labels = goodness_per_label.argmax(dim=1)\n",
    "            correct += (predicted_labels == actual_labels).sum().item()\n",
    "            total += batch_size\n",
    "    \n",
    "        accuracy = correct / total\n",
    "        return accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-05T13:16:29.195069500Z",
     "start_time": "2024-09-05T13:16:29.189067500Z"
    }
   },
   "id": "353cd10d7b3259d2"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.19172 in 1 epochs\n",
      "Testing Acc: 0.1957 in 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.22896 in 2 epochs\n",
      "Testing Acc: 0.231 in 2 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.25428 in 3 epochs\n",
      "Testing Acc: 0.2578 in 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.27688 in 4 epochs\n",
      "Testing Acc: 0.2805 in 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.2858 in 5 epochs\n",
      "Testing Acc: 0.2899 in 5 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.294 in 6 epochs\n",
      "Testing Acc: 0.2992 in 6 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.30126 in 7 epochs\n",
      "Testing Acc: 0.305 in 7 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.30838 in 8 epochs\n",
      "Testing Acc: 0.3108 in 8 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.31094 in 9 epochs\n",
      "Testing Acc: 0.3153 in 9 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.31478 in 10 epochs\n",
      "Testing Acc: 0.3174 in 10 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.31616 in 11 epochs\n",
      "Testing Acc: 0.317 in 11 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.31934 in 12 epochs\n",
      "Testing Acc: 0.3206 in 12 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.3212 in 13 epochs\n",
      "Testing Acc: 0.3227 in 13 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.32484 in 14 epochs\n",
      "Testing Acc: 0.3258 in 14 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.32646 in 15 epochs\n",
      "Testing Acc: 0.328 in 15 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.3271 in 16 epochs\n",
      "Testing Acc: 0.3286 in 16 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.32912 in 17 epochs\n",
      "Testing Acc: 0.3306 in 17 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.33232 in 18 epochs\n",
      "Testing Acc: 0.3308 in 18 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.33292 in 19 epochs\n",
      "Testing Acc: 0.3326 in 19 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc: 0.33572 in 20 epochs\n",
      "Testing Acc: 0.3382 in 20 epochs\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.manual_seed(1234)\n",
    "    network = CustomNetwork().cuda()\n",
    "    for i in range(20):\n",
    "        network.train_network(trainloader)\n",
    "        training_acc = network.predict(trainloader)\n",
    "        testing_acc = network.predict(testloader)\n",
    "        print(f\"Training Acc: {training_acc} in {(i+1) * number_of_epochs} epochs\")\n",
    "        print(f\"Testing Acc: {testing_acc} in {(i+1) * number_of_epochs} epochs\")\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-05T13:23:59.007990Z",
     "start_time": "2024-09-05T13:16:29.196078300Z"
    }
   },
   "id": "4680eee788c638f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
